### What's in this repo?

This repo simply contains usage of the existing GPT-2 code for finetuning the 117M model for three particular use-cases:
* Short Stories
* Game of Thrones (books)
* Essays

All of the modified code is present [here](src/custom_scripts/)

If you want to see a nice poster which summarizes our findings, you can find it [here](poster/poster.pdf)